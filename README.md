# ğŸ¨ ImplÃ©mentation de Concept Sliders sur CryptoPunks

> Tentative de reproduction de la mÃ©thode "Concept Sliders" pour la gÃ©nÃ©ration conditionnelle de CryptoPunks.

## ğŸ¯ Objectif du Projet

Ce projet vise Ã  **reproduire la mÃ©thode "Concept Sliders"** dÃ©crite dans le papier :

> **Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models**  
> Gandikota et al., 2023 ([arXiv:2311.17216](https://arxiv.org/abs/2311.17216))

L'idÃ©e est d'apprendre des **vecteurs concepts** qui permettent de contrÃ´ler des attributs sÃ©mantiques (accessoires : casquette, pipe, cigarette, hoodie) dans un modÃ¨le de diffusion, sans rÃ©entraÃ®ner le modÃ¨le complet.

---

## ğŸ—ï¸ MÃ©thodologie ImplÃ©mentÃ©e

### Ã‰tape 1 : EntraÃ®nement du DDPM de base

EntraÃ®nement d'un UNet pour prÃ©dire le bruit `Îµ` avec un concept vector nul (`c = 0`).

```
Loss : min_Î¸ E||Îµ - Îµ_Î¸(x_t, t, c=0)||Â²
```

**Fichiers :**
- [src/model_vector.py](src/model_vector.py) : Architecture UNet avec injection de concept au bottleneck
- [src/train_ddpm.py](src/train_ddpm.py) : Script d'entraÃ®nement du DDPM de base
- [src/diffusion.py](src/diffusion.py) : Processus de diffusion (forward/reverse)

### Ã‰tape 2 : Apprentissage des Concept Vectors

AprÃ¨s avoir gelÃ© le modÃ¨le DDPM prÃ©-entraÃ®nÃ©, on optimise un vecteur `c_k` pour chaque concept (accessoire) sur un sous-ensemble d'images filtrÃ©.

```
Loss : min_{c_k} E||Îµ - Îµ_Î¸(x_t, t, c_k)||Â²
```

L'injection se fait au bottleneck du UNet :
```
h' = h + Î± Â· c_k
```

oÃ¹ `h` est la reprÃ©sentation latente (512D) et `Î±` est un facteur d'Ã©chelle.

**Fichiers :**
- [src/train_concepts.py](src/train_concepts.py) : Optimisation des vecteurs concepts
- [src/create_subdatasets.py](src/create_subdatasets.py) : CrÃ©ation des sous-datasets par accessoire
- `concepts/` : Vecteurs concepts sauvegardÃ©s (`acc_cap.pt`, `acc_pipe.pt`, etc.)

### Ã‰tape 3 : GÃ©nÃ©ration avec Combinaison de Concepts

Ã€ l'infÃ©rence, on combine linÃ©airement les concepts :
```
c = Î£_k Î²_k Â· c_k
```

**Fichiers :**
- [src/generate_concepts.py](src/generate_concepts.py) : GÃ©nÃ©ration avec injection de concepts
- [src/generate_with_concepts.py](src/generate_with_concepts.py) : Interface de gÃ©nÃ©ration

---

## âŒ ProblÃ¨me RencontrÃ© : Ã‰chec de l'Apprentissage

### Observation

Pendant l'entraÃ®nement des concept vectors, **la norme des vecteurs `c_k` augmentait continuellement** au lieu de converger vers une reprÃ©sentation stable.

```
Epoch 1:   |c| = 0.05
Epoch 10:  |c| = 2.3
Epoch 50:  |c| = 15.7
Epoch 100: |c| = 45.2   â† divergence
```

### Analyse

Les vecteurs concepts n'arrivaient pas Ã  apprendre correctement dans l'espace latent `h` du bottleneck :

1. **Espace non structurÃ©** : Le modÃ¨le DDPM a Ã©tÃ© entraÃ®nÃ© avec `c = 0`, donc l'espace latent n'a jamais Ã©tÃ© exposÃ© Ã  des variations de concepts. L'injection additive `h' = h + Î±Â·c` perturbe un espace qui n'a pas Ã©tÃ© conÃ§u pour Ã§a.

2. **Optimisation instable** : Sans contrainte, l'optimiseur pousse `||c_k||` â†’ âˆ pour minimiser la loss, car augmenter la norme permet de "forcer" le modÃ¨le Ã  produire des prÃ©dictions plus proches des images cibles.

3. **Pas de rÃ©gularisation** : Contrairement au papier original qui utilise des LoRA (faible rang, rÃ©gularisation implicite), notre approche avec un vecteur dense 512D n'a pas de contrainte structurelle.

4. **Distribution des features** : L'injection `h + Î±Â·c` peut faire sortir les features de leur distribution d'entraÃ®nement, causant des artefacts.

### Tentatives de correction (sans succÃ¨s)

- RÃ©gularisation L2 sur `||c_k||`
- Diminution du learning rate
- Early stopping basÃ© sur la norme
- DiffÃ©rentes valeurs de `Î±` (concept_scale)

---

## ğŸ“ Structure du Projet

```
.
â”œâ”€â”€ concepts/                       # Vecteurs concepts (tentative Ã©chouÃ©e)
â”‚   â”œâ”€â”€ acc_cap.pt
â”‚   â”œâ”€â”€ acc_cigarette.pt
â”‚   â”œâ”€â”€ acc_hoodie.pt
â”‚   â””â”€â”€ acc_pipe.pt
â”œâ”€â”€ models/
â”‚   â””â”€â”€ CRYPTOPUNKS/                # ModÃ¨le DDPM de base
â”‚       â””â”€â”€ cryptopunks1/
â”‚           â””â”€â”€ ckpt_final.pt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model_vector.py             # UNet avec injection concept
â”‚   â”œâ”€â”€ train_ddpm.py               # EntraÃ®nement DDPM (c=0)
â”‚   â”œâ”€â”€ train_concepts.py           # Apprentissage concepts (Ã‰CHEC)
â”‚   â”œâ”€â”€ generate_concepts.py        # GÃ©nÃ©ration avec concepts
â”‚   â”œâ”€â”€ diffusion.py                # Process de diffusion
â”‚   â””â”€â”€ config.py                   # Configurations
â””â”€â”€ runs/                           # Logs TensorBoard
```

---

## âš™ï¸ Configuration

| ParamÃ¨tre | Valeur | Description |
|-----------|--------|-------------|
| `T` | 1000 | Nombre de timesteps de diffusion |
| `img_size` | 32 | Taille des images (32Ã—32) |
| `concept_dim` | 512 | Dimension des vecteurs concepts |
| `concept_scale` | 1.0 | Facteur Î± pour l'injection |
| `lr` (concepts) | 1e-3 | Learning rate pour l'apprentissage des concepts |
| `init_std` | 0.01 | Ã‰cart-type d'initialisation `c ~ N(0, ÏƒÂ²)` |

---

## ğŸš€ Utilisation

### 1. EntraÃ®ner le DDPM de base

```bash
python src/train_ddpm.py --config cryptopunks1 --epochs 100
```

### 2. CrÃ©er les sous-datasets par accessoire

```bash
python src/create_subdatasets.py
```

### 3. Apprendre un concept (rÃ©sultats non satisfaisants)

```bash
python src/train_concepts.py \
    --checkpoint models/CRYPTOPUNKS/cryptopunks1/ckpt_final.pt \
    --concept cap \
    --epochs 100
```

### 4. GÃ©nÃ©rer avec concepts

```bash
python src/generate_concepts.py \
    --checkpoint models/CRYPTOPUNKS/cryptopunks1/ckpt_final.pt \
    --concepts cap pipe \
    --weights 1.0 0.5 \
    --n 4
```

---

## ğŸ“š RÃ©fÃ©rences

- [Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models (Gandikota et al., 2023)](https://arxiv.org/abs/2311.17216)
- [Denoising Diffusion Probabilistic Models (Ho et al., 2020)](https://arxiv.org/abs/2006.11239)
- [CryptoPunks Dataset](https://www.kaggle.com/datasets/chwasiq0569/cryptopunks-pixel-art-dataset)

---

## âœ… Approche Alternative (Fonctionnelle)

Face Ã  l'Ã©chec de la mÃ©thode Concept Sliders, une approche alternative a Ã©tÃ© implÃ©mentÃ©e : **entraÃ®ner le modÃ¨le directement avec conditionnement sur les accessoires**.

- [src/model_conditioned.py](src/model_conditioned.py) : UNet avec embedding learnable (multi-hot â†’ concept 512D)
- [src/train_ddpm_conditioned.py](src/train_ddpm_conditioned.py) : EntraÃ®nement end-to-end avec CFG dropout
- [app.py](app.py) : Interface Streamlit pour la gÃ©nÃ©ration

Cette approche fonctionne car le modÃ¨le apprend dÃ¨s le dÃ©part Ã  utiliser les vecteurs d'accessoires, plutÃ´t que d'essayer d'injecter des concepts dans un espace non prÃ©parÃ©.

```bash
# EntraÃ®nement conditionnÃ©
python src/train_ddpm_conditioned.py --epochs 50

# Interface de gÃ©nÃ©ration
streamlit run app.py
```

---

## ğŸ“„ Licence

MIT License

## ğŸ“„ Licence

MIT License - voir [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ‘¤ Auteur

Projet Deep Learning - EPITA S9 (2025-2026)
